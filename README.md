# ğŸ“§ Email Classifier API

[![Tests](https://img.shields.io/badge/tests-44%20passing-brightgreen)](https://github.com/Brunotlps/email-classifier)
[![Coverage](https://img.shields.io/badge/coverage-79%25-yellowgreen)](https://github.com/Brunotlps/email-classifier)
[![Python](https://img.shields.io/badge/python-3.11-blue)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.0-009688)](https://fastapi.tiangolo.com/)

Classificador inteligente de emails usando IA (Ollama/OpenAI) que identifica emails produtivos/improdutivos e gera sugestÃµes de resposta contextualmente relevantes.

---

## ğŸ¯ Funcionalidades

- âœ… ClassificaÃ§Ã£o automÃ¡tica de emails (produtivo vs improdutivo)
- âœ… GeraÃ§Ã£o de sugestÃµes de resposta com mÃºltiplos tons (formal, cordial, casual, tÃ©cnico)
- âœ… Suporte para Ollama (dev) e OpenAI (prod)
- âœ… Upload de arquivos (.txt, .eml, .pdf)
- âœ… API REST totalmente documentada (Swagger)
- âœ… 44 testes automatizados com 79% de cobertura

---

## ğŸš€ Tecnologias

**Backend**: FastAPI 0.115.0 + Python 3.11  
**IA**: Ollama (qwen2.5:3b) / OpenAI (gpt-3.5-turbo)  
**Testes**: pytest + pytest-asyncio (44 testes, 79% coverage)  
**Deploy**: Docker + Docker Compose

---

## ğŸ—ï¸ DecisÃµes de Arquitetura

### Por que FastAPI?
- **Performance**: Async nativo ideal para chamadas de IA (I/O-bound)
- **DocumentaÃ§Ã£o automÃ¡tica**: Swagger gerado automaticamente
- **ValidaÃ§Ã£o**: Pydantic integrado reduz bugs

### Por que Ollama + OpenAI?
- **Ollama**: Desenvolvimento local sem custos, privado
- **OpenAI**: ProduÃ§Ã£o com qualidade superior
- **AbstraÃ§Ã£o**: Factory pattern permite trocar facilmente

### Arquitetura em Camadas
```
API Layer (routes.py)
    â†“
Service Layer (classifier, response_generator)
    â†“
Utils Layer (ai_client, file_parser)
```

**BenefÃ­cios**: Testabilidade, manutenibilidade, baixo acoplamento

## ğŸ“¦ InstalaÃ§Ã£o RÃ¡pida

### PrÃ©-requisitos

- Docker e Docker Compose
- Ollama instalado e configurado

### 1. Instalar Ollama

```bash
# Instalar
curl -fsSL https://ollama.com/install.sh | sh

# Baixar modelo
ollama pull qwen2.5:3b

# Configurar para aceitar conexÃµes externas (IMPORTANTE!)
sudo systemctl edit ollama
```

Adicione no editor:
```ini
[Service]
Environment="OLLAMA_HOST=0.0.0.0:11434"
```

Salve e reinicie:
```bash
sudo systemctl daemon-reload
sudo systemctl restart ollama
```

### 2. Clonar e Configurar

```bash
git clone https://github.com/Brunotlps/email-classifier.git
cd email-classifier

# Criar .env (use .env.example como base)
cp .env.example .env
```

### 3. Executar

```bash
# Subir aplicaÃ§Ã£o
docker-compose up -d

# Verificar logs
docker-compose logs -f
```

**Acesse**: http://localhost:8001/docs

---

## ğŸ“š Uso da API

### Classificar Email

```bash
curl -X POST http://localhost:8001/api/v1/classify \
  -H "Content-Type: application/json" \
  -d '{
    "email_content": "OlÃ¡, gostaria de agendar uma reuniÃ£o para discutir parceria."
  }'
```

**Resposta:**
```json
{
  "classification": "produtivo",
  "confidence": 0.92,
  "reasoning": "Email solicita reuniÃ£o, demonstra interesse comercial",
  "suggestions": [
    {
      "title": "Resposta cordial",
      "content": "OlÃ¡! AgradeÃ§o o contato. Podemos agendar para...",
      "tone": "cordial"
    }
  ]
}
```

### Upload de Arquivo

```bash
curl -X POST http://localhost:8001/api/v1/classify-file \
  -F "file=@email.txt"
```

---

## ğŸ§ª Testes

```bash
# Rodar testes
docker exec -it email_classifier_api pytest tests/ -v

# Com cobertura
docker exec -it email_classifier_api pytest tests/ --cov=app --cov-report=term
```

**Resultado**: 44 testes passando, 79% de cobertura âœ…

---

## ğŸ“ Estrutura

```
email-classifier/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/routes.py              # Endpoints REST
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ classifier.py          # LÃ³gica de classificaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ response_generator.py  # GeraÃ§Ã£o de sugestÃµes
â”‚   â”œâ”€â”€ models/schemas.py          # ValidaÃ§Ã£o Pydantic
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ ai_client.py           # Cliente Ollama/OpenAI
â”‚   â”‚   â””â”€â”€ file_parser.py         # Parser multi-formato
â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes
â”‚   â””â”€â”€ main.py                    # FastAPI app
â”œâ”€â”€ tests/                         # 44 testes automatizados
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

---

## ğŸ”§ Troubleshooting

### Erro de ConexÃ£o com Ollama

```
Connection refused
```

**SoluÃ§Ã£o**: Verifique se o Ollama estÃ¡ configurado para aceitar conexÃµes externas (ver passo 1 da instalaÃ§Ã£o).

```bash
# Verificar
sudo systemctl status ollama | grep Listening
# Deve mostrar: [::]:11434 ou 0.0.0.0:11434
```

### Porta 8001 em Uso

```bash
# Verificar processo
sudo lsof -i :8001

# Ou alterar porta no docker-compose.yml
ports:
  - "8002:8000"
```

---

## ğŸ“Š Cobertura de Testes

| Componente | Cobertura |
|------------|-----------|
| Schemas | 100% âœ… |
| Classifier | 98% âœ… |
| Response Generator | 98% âœ… |
| Main | 86% âœ… |
| Config | 85% âœ… |
| **Total** | **79%** âœ… |

---

## ğŸ¯ PrÃ³ximos Passos

1. âœ… **Backend completo** com testes
2. ğŸ”„ **Frontend** bÃ¡sico em desenvolvimento
3. ğŸ“¦ **Deploy** planejado (Vercel/Railway)

---

## ğŸ‘¤ Autor

**Bruno Teixeira**  
[![GitHub](https://img.shields.io/badge/GitHub-Brunotlps-181717?logo=github)](https://github.com/Brunotlps)

---

## ğŸ“ LicenÃ§a

Projeto educacional desenvolvido para processo seletivo de estÃ¡gio em Engenharia de Software.

---

**Desenvolvido utilizando FastAPI + Ollama**