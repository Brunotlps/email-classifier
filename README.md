# ğŸ“§ Email Classifier API

Classificador de emails usando IA (Ollama/OpenAI) que determina se um email Ã© produtivo ou improdutivo e gera sugestÃµes de resposta.

## ğŸš€ Tecnologias

- **Backend**: FastAPI + Python 3.11
- **IA**: Ollama (desenvolvimento) / OpenAI (produÃ§Ã£o)
- **ContainerizaÃ§Ã£o**: Docker + Docker Compose
- **ValidaÃ§Ã£o**: Pydantic

## ğŸ“‹ PrÃ©-requisitos

- Docker e Docker Compose
- Ollama (para desenvolvimento local)
- Python 3.11+ (para testes locais)

## âš™ï¸ ConfiguraÃ§Ã£o do Ollama (Linux)

**IMPORTANTE**: Por padrÃ£o, o Ollama escuta apenas em `localhost`. Para funcionar com Docker, precisa aceitar conexÃµes externas:

```bash
# 1. Criar/editar arquivo de configuraÃ§Ã£o do systemd
sudo mkdir -p /etc/systemd/system/ollama.service.d
sudo nano /etc/systemd/system/ollama.service.d/override.conf

# 2. Adicionar estas linhas:
[Service]
Environment="OLLAMA_HOST=0.0.0.0:11434"

# 3. Recarregar e reiniciar
sudo systemctl daemon-reload
sudo systemctl restart ollama

# 4. Verificar se estÃ¡ escutando em todas as interfaces
sudo systemctl status ollama | grep Listening
# Deve mostrar: "Listening on [::]:11434"

# 5. Testar conectividade
curl http://localhost:11434/api/version
curl http://172.21.0.1:11434/api/version  # IP do gateway Docker
```

## ğŸ³ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Instalar Ollama

```bash
# Instalar
curl -fsSL https://ollama.com/install.sh | sh

# Baixar modelo
ollama pull qwen2.5:3b

# Configurar para aceitar conexÃµes externas (ver seÃ§Ã£o acima)
```

### 2. Configurar variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
ENVIRONMENT=development
AI_PROVIDER=ollama

# OpenAI (opcional, para produÃ§Ã£o)
OPENAI_API_KEY=sua-chave-aqui
OPENAI_MODEL=gpt-3.5-turbo

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b

# ConfiguraÃ§Ãµes de IA
MAX_TOKENS=500
TEMPERATURE=0.7
```

### 3. Subir a aplicaÃ§Ã£o

```bash
# Subir container
docker-compose up --build

# Ou em background
docker-compose up -d
```

### 4. Acessar

- **API**: http://localhost:8001
- **DocumentaÃ§Ã£o**: http://localhost:8001/docs
- **Health Check**: http://localhost:8001/health
- **Teste de IA**: http://localhost:8001/test-ai

## ğŸ§ª Testes

### Teste local (fora do Docker)

```bash
# Ativar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# Rodar teste
python test_ai.py
```

### Teste no container

```bash
# Verificar URL configurada
docker exec email_classifier_api python -c "from app.config import settings; print(settings.ollama_base_url)"

# Testar conectividade Ollama
docker exec email_classifier_api python -c "import httpx; print(httpx.get('http://172.21.0.1:11434/api/version', timeout=5.0).json())"

# Testar endpoint
curl http://localhost:8001/test-ai
```

## ğŸ“ Estrutura do Projeto

```
email-classifier/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py        # Endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ classifier.py    # LÃ³gica de classificaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ response_generator.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py       # Modelos Pydantic
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ ai_client.py     # Cliente de IA (Ollama/OpenAI)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ test_ai.py
â””â”€â”€ README.md
```

## ğŸ”§ Troubleshooting

### Container nÃ£o conecta ao Ollama

**Erro**: `[Errno -2] Name or service not known`

**SoluÃ§Ã£o**: Verifique se o Ollama estÃ¡ configurado para aceitar conexÃµes externas (ver seÃ§Ã£o "ConfiguraÃ§Ã£o do Ollama")

```bash
# Verificar se estÃ¡ escutando em todas as interfaces
sudo systemctl status ollama | grep Listening
```

### Porta 8001 jÃ¡ em uso

```bash
# Ver o que estÃ¡ usando a porta
sudo lsof -i :8001

# Matar processo (substitua PID)
kill -9 <PID>
```

### Hot-reload nÃ£o funciona

Verifique se os volumes estÃ£o corretos no `docker-compose.yml`:

```yaml
volumes:
  - ./app:/app/app  # Sincroniza pasta local com container
```

## ğŸš€ PrÃ³ximos Passos

- [ ] Implementar serviÃ§o de classificaÃ§Ã£o
- [ ] Criar endpoint `/classify`
- [ ] Adicionar geraÃ§Ã£o de sugestÃµes de resposta
- [ ] Criar frontend
- [ ] Adicionar testes unitÃ¡rios
- [ ] Deploy em produÃ§Ã£o

## ğŸ“ LicenÃ§a

Projeto desenvolvido para processo seletivo de estÃ¡gio em Engenharia de Software.